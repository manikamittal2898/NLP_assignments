It is a typical day and we are scrolling through our Google news feed as it tells us about the elections and the policies our favoured political party intends to implement, yesterday’s match that our favourite team lost by 3-1, and the box office collection of the movie we watched last weekend. We do this ‘harmless’ skimming and sharing and clicking almost every day as we wait for the lift to reach our floor, to grapple with insomnia, or to try to stay awake in a boring morning lecture. But what most of us fail to notice is that whatever we are seeing or reading is always about ‘us’. The content that the Internet offers us is already curated by some ‘intelligent’ forces behind our screens to ensure that it matches with our interests. But the important question that arises is that- ‘ Is personalisation to this extent actually required?’ More than that- ‘ Is this kind of curation and filtering actually in our personal interest and society as a whole?’ In today’s era, when Internet rules our lives and AI is the future, getting the answer to these questions is of prime importance.

According to Wikipedia- the term ‘filter bubble’ means a state of intellectual isolation that allegedly can result from personalised searches when a website algorithm selectively guesses what information a user would like to see based on information about the user such as location, past- click behaviour and search history. Prime examples include Google personalised search and Facebook personalised news stream. As a result, users get separated from the information that challenges their already existing viewpoints, thereby effectively isolating them in a biased world fabricated by their own perceptions and opinions.

The term ‘filter bubble’ was coined by Eli Parser, an Internet activist who made the world aware of the potential threat offered by the personalising algorithms that intend to improve our online experience. He called the filter bubble a “ personal ecosystem of information, kind of invisible auto propaganda, indoctrinating us with our own ideas, amplifying our desire for things that are familiar and leaving us oblivious to the dangers lurking in the dark territory of the unknown”. It insulates us from any sort of cognitive dissonance by limiting what we see. At the same time, it virtually monitors everything we do online for someone else’s benefit.

The filter bubble phenomenon is clearly harmful because it causes the information on the Web to be always presented to us from a particular point of view. This not only affects our psyche on a fundamental level but also traps us in our own ideological sphere. One of its major negative consequences is that when we get trapped in a filter bubble, we don’t get exposed to information that could challenge or broaden our worldview. Since we get to view only one side of the story, that naturally reinforces our own beliefs and moves us into having biased opinions.

On the Internet what we see is what these personalisation algorithms want us to see which is not necessarily what we should see. My search results for a particular word differ greatly from that of yours as the Web content is customised for each one of us. We all have our own unique universe of information and interestingly, we all usually don’t realize it. In fact, the worst part of this phenomenon is that it works almost invisibly, to affect our psyche and formulate our opinions based on our already existing biases without us even getting to know about it. We are deprived of a balanced flow of information and we are unaware of it as this ‘intelligent’ agent works in an unimaginably discreet manner. The most destructive outcome of the filter bubble effect is that it gives us a false impression that our narrow, curated view of the world is the actual picture of the entire universe.

The same Internet which was created to serve as a medium to connect us to the rest of the world intellectually while relaxing in the comfort of our homes is now isolating us in our own mini-worlds. We all are aware of how the filter bubble effect was responsible for the alleged foreign interference in the 2016 US elections, thereby leading to cyber warfare. No wonder even India faces the same threat as it gears up for 2019 general elections unless some strict measures are taken. There is a dire need to burst this bubble before it becomes cataclysmic to us and the society in general as Eric Schmidt said, “It will be very hard for people to watch or consume something that has not in some sense been tailored for them.” The first step on the path of avoiding the harmful effects of filter bubbles is to recognise when we are inside one. To this end, it is helpful if the applications we use clearly indicate that the recommendations that we see don’t represent a balanced overall view to the content. So, if algorithms are going to curate the world for us, it is necessary to ensure that they are not only hooked to relevance but also show content that is challenging or important. Recommendation system algorithms should have encoded in them a sense of civic responsibility, public life and general humanity. Trending information should be made available to users irrespective of the fact whether it is their personal preference or not. Users should be given some control in deciding what gets through the filter and what doesn’t. They should be able to control and modify the extent of personalisation they receive in their feed. Lastly, we as users should browse responsibly and not allow the content available online to sway us or influence our actions and decisions.
